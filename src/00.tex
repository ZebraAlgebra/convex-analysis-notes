\chapter*{Preface}

\paragraph{}This note started as a personal note on the book \cite{bertsekas2009convex}, which the author found immense joy going through it. The intent was to refactor some of the proofs, presentations of contents in a different style. Sometimes, alternative proofs are given. Gradually, I decided to organize this note into its current form.

\paragraph{}This book assumes some familiarity with point set topology, calculus, and linear algebra. Also, some contents are omitted - such as minimax problems, theorems on alternatives, nonconvex optimization; the interested readers are encouraged to consult \cite{bertsekas2009convex} for relevant treatments.

\paragraph{}In \Cref{chap:01}, we define convex sets. The basic topology and geometry of convex sets are also studied in this chapter, including dimension, the construction of relative interiors, and the notion of recession cones. Several important yoga on the construction of convex sets are given here. We also include treatment on polyhedral sets, which occurs frequently as feasibility regions arising from affine constraints.

\paragraph{}In \Cref{chap:02}, we define convex functions. This chapter starts with the construction of epigraphs, which are geometric objects associated to functions taking values in the extended real line, allowing us to construct associated functions using topological, geometrical methods. Epigraphs are also used for defining functional properties that can be described via properties of its epigraphs. Lastly, we define the convex conjugate of a function, which would serve as an entry point for MC/MC duality theory.

\paragraph{}In \Cref{chap:03}, the MC/MC (max-crossing/min-common) duality framework is given, using convex conjugates as motivation. We give several results on the relation between the MC/MC values, as well as criterions for attainability of optimal values that will arise in later chapters.

\paragraph{}In \Cref{chap:04}, we apply MC/MC duality to derive several duality results in convex optimization. The first fundamental result is the Farkas lemma, both the linear version and the nonlinear version are given here. Using Farkas lemma, we derive linear optimization duality and convex optimization duality, introduce Slater's conditions, complementary slackness. After that, we define subgradients via te MC/MC framework.

\chapter*{Notations and Conventions}

\paragraph{}Here we lay out some notations and conventions used throughout this note.

\paragraph{Standard sets}We use $\mathbb{R,N,Z}$ to denote the real numbers, natural numbers, integers, with the convention $0\notin \mathbb{N}$. We also use $\overline{\mathbb{R}}$ to denote $\mathbb{R}\cup\{\pm\infty\}=[-\infty,+\infty]$, $\mathbb{R}_{+}=[0,+\infty)$, $\mathbb{R}_{++}=(0,+\infty)$.

\paragraph{Metric Space-related Constructions}For a subset of $X\subset \mathbb{R}^m$, we use $\operatorname{cl}(X),\operatorname{int}(X),\operatorname{bdy}(X)$ to denote the closure, interior, boudnary of $X$ under the metric space topology. For an element $x\in \mathbb{R}^m$, we use $\|x\|$ to denote its $2$-norm; in general, the $p$-norm of $x$ is denoted as $\|x\|_p$. Given $\varepsilon \in \mathbb{R}_{+}$ and $x\in \mathbb{R}^m$, the open ball with radius $\varepsilon$ is denoted as $B(x;\varepsilon )$, defined as the set $\{y\in \mathbb{R}^m:\|x-y\|<\varepsilon \}$; more generally, given $X\subset \mathbb{R}$, we write $B(X;\varepsilon )=\bigcup_{x\in X}B(x;\varepsilon )$. The unit sphere $\mathbb{S}^{m-1}\subset \mathbb{R}^m$ is defined as the set $\{x\in \mathbb{R}^m:\|x\|=1\}$.

\paragraph{Extension by Infinity}Given $f:X\to\overline{\mathbb{R}}$ with $X\subset \mathbb{R}^m$, for optimization purpose we can extend it by infinity out side of $X$, yielding a function $\overline{f}:\mathbb{R}^m\to\overline{\mathbb{R}}$ so that $\overline{f}\mid_{\mathbb{R}^m\smallsetminus X}$ is constant with value $\infty$. Therefore we often assume $f$ is defined over all $\mathbb{R}^m$.

\paragraph{Fibers and Slices}Given $Z\subset \mathbb{R}^{k}\times \mathbb{R}^{m-k}=\mathbb{R}^m$, and $x\in \mathbb{R}^k,y\in \mathbb{R}^{m-k}$, we call $Z_{x,:}:=\{y\in \mathbb{R}^{m-k}:(x,y)\in Z\}$ and $Z_{:,y}:=\{x\in \mathbb{R}^{k}:(x,y)\in Z\}$ the fiber at $x$ and the slice at $y$. Most of the time, $k=m-1$.

\paragraph{Sequences of points or subsets}An indexed set of elements in a set $S$ indexed by an index set $\mathcal{I}$ will be written as $\{x_i\}_{i\in \mathcal{I}}\subset S$. When the indexing set is omitted, the indexing set is assumed to be $\mathbb{N}$. Given a sequence $\{x_i\}_{i=1}^\infty$, we write $\{x_i\}_i\to x$ if $x_i$ converges to $x$ in $2$-norm. Given a sequence of subsets $\left\{C_i\right\}_{i}$ of $\mathbb{R}^n$, we say that it is an ascending chain if $C_1\subset C_2\subset \dotsc$, and a descending chain if $C_1\supset C_2\supset \dotsc$. The consideration of a union of an ascending chain or an intersection of a descending chain of sets are things that occurs frequently in analysis.

\paragraph{Representation of Elements in $\mathbb{R}^m$}For $m>1$, we thought of elements in $\mathbb{R}^m$ as column vectors. The origin is denoted as $O_m$, or $O$ if the context is clear. The standard basis is written as $\{e_i^m\}_{i=1}^m$ or $\{e_i\}_{i=1}^m$ if the context is clear, with the convention $e_0=O$. Given $x,y\in \mathbb{R}^m$, we write $x\leq y$ if $x_i\leq y_i$ for $i=1,\dotsc,m$.

\paragraph{Matrices}The space of $m$ by $n$ matrices (or: linear maps $\mathbb{R}^m\to \mathbb{R}^n$) with real valued entries is denoted as $\mathbf{M}_{n,m}(\mathbb{R})$. Given $A\in \mathbf{M}_{n,m}(\mathbb{R})$, its $i$-th row (resp. column) is denoted as $A_{i,:}$ (reps. $A_{:,i}$). When $m=n$, the identity matrix is written as $I_m$.


