\section{Technical Lemmas}
\label{sect:014}

\paragraph{}We compile a list of technical lemmas for the development of the subsequent sections and chapters, as these are of relative little importance at the conceptual level, but useful as technical tools.

\subsection{Projection to Convex Subset}
\paragraph{}A special property of closed convex set is that one can define projection maps onto them. For general nonempty convex sets, analogous statements holds on their closures.

\begin{lemm}[Projection Lemma]\label{lemm:014-projection}
	Given a nonempty closed convex set $C\subset \mathbb{R}^m$ and a point $x\in \mathbb{R}^m$, then:
	\begin{enumerate}[label=(\alph*)]
		\item (Well-definedness of Projection) There is a unique $y_0\in C$ with $\|y_0-x\|^2=\inf_{y\in C}\|y-x\|^2$.
		\item (Optimality Condition) Such $y_0$ is characterized as the unique point with the property:
		      \[
			      (y-y_0)^T(x-y_0)\leq 0,\;\text{ for all }y\in C
		      \]
	\end{enumerate}
	Such a point is called the projection of $x$ on $C$.
\end{lemm}

\begin{proof}
	By translation, may assume $x=0$, then we are looking at points in $C$ with minimal norm. Let $f:\mathbb{R}^m\to \mathbb{R}$ be the function $y\mapsto \|y\|^2$. To show existence, one can assume $C$ is nonempty compact by restricting to a bounded subset, then $f(C)$ is compact, so a minimum is attained. For optimality condition ($(y-y_0)^Ty_0\geq 0$ for $y\in C$), suppose $y_0$ is optimal and $y\in C$, then for $\alpha \in(0,1]$:
	\[
		\alpha^{-1}\left(f(I(y_0,y; \alpha ))-f(y_0)\right) = (2y_0 + \alpha (y-y_0))^T(y-y_0)\geq0
	\]
	so by taking $\alpha \to 0^+$, we see that an optimal $y_0$ satisfies the given optimal condition. Once uniqueness is established, we are done. If $y_0,y'_0$ are both optimal, let $y_0''=I(y_0,y_0';1/2)$, then by triangle inequality, we have $f(y_0'')=\|y_0+y_0'\|^2/4\leq (\|y_0\|+\|y_0'\|)^2/4 =f(y_0)$ with "$=$" holding iff $y_0=y_0'$.
\end{proof}

\subsection{Intersection Theorems}

\paragraph{}Let $\{C_i\}_i$ be a descending chain of non-empty closed sets in $\mathbb{R}^m$, and let $C=\bigcap_iC_i$. We know that when some $C_i$ is compact, then $C\neq\emptyset$. For closed convex sets, we seek conditions where $C\neq\emptyset$. One such condition is the "retractive condition" (see \Cref{defn:014-retractiveness}, \Cref{prop:014-non-empt-I}). In some cases, retractive condition can be implied from the sets $R:=\bigcap_i R_{C_i},L:=\bigcap_i L_{C_i}$ (see \Cref{prop:014-non-empt-II}). For this subsection, let us assume that $\{C_i\}_i$ is a descending chain of nonempty closed convex subsets.
\paragraph{}A modification of the proof of (e) of \Cref{prop:013-yoga-recession} yields the following:

\begin{prop}[Construction of Recession Directions]
	\label{prop:014-construction-recession}
	Given $\{x_i\}_i\subset \mathbb{R}^m\smallsetminus \{0\}$ with $\{\|x_i\|\}_i\to\infty$, $x_i\in C_i$, then all limit points of $\{\nu(x_i)\}_i\subset \mathbb{S}^{m-1}$ are contained in $R\cap \mathbb{S}^{m-1}$.
\end{prop}

\paragraph{}In other words, $\nu(R)$ and hence $R$ can be characterized completely via \Cref{prop:014-construction-recession}. The special case where $C_i=C_0$ for some fixed $C_0$ gives (d) of \Cref{prop:013-yoga-recession}. This motivates the following definition:

\begin{defn}[Asymptotic Sequences]
	\label{defn:014-asymptotic}
	A sequence $\{x_i\}_i\subset \mathbb{R}^m\smallsetminus\{0\}$ is an asymptotic sequence of $\{C_i\}_i$ if $\{\|x_i\|\}_i\to\infty$, $x_i\in C_i$, and that $\{\nu_i(x)\}_i\subset \mathbb{S}^{m-1}$ converges to some $d\in \mathbb{S}^{m-1}$.
\end{defn}

\begin{defn}[Retractiveness]
	\label{defn:014-retractiveness}
	An asymptotic sequence $\{x_i\}_i$ with $\{\nu(x_i)\}_i\to d\in R\cap \mathbb{S}^{m-1}$ is retractive if $x_i-d\in C_i$ for all $i\geq i_0$ for some $i_0$. The sequence $\{C_i\}_i$ is retractive if all asymptotic sequences are retractive. A convex set $C_0$ is retractive if $\{C_0\}_i$ is retractive.
\end{defn}

\paragraph{}Note that a subsequence of a retractive sequence of closed convex sets is still retractive.

\begin{rmrk}
	In \cite{bertsekas2009convex}, retractive sequences of convex sets needs to have the condition that for any $\lambda >0$ and asymptotic sequences $\{x_i\}_i$ with $\{\nu(x_i)\}_i\to d$, $x_i-\lambda d\in C_i$ for all $i\geq i_0$ for some $i_0$. One can show that this coincides with the one given in \Cref{defn:014-retractiveness}, by repeatedly applying the transformation $\{x_i\}_i\mapsto \{x_i-d\}_i$.
\end{rmrk}

\begin{prop}[Non-empty Intersection I]
	\label{prop:014-non-empt-I}
	Suppose $\{C_i\}_i$ is retractive, then $C\neq\emptyset$.
\end{prop}

\begin{proof}
	Take the sequence $\{x_i\}_i$ defined by $\|x_i\|=\inf_{x\in C_i}\|x\|$ (see \Cref{lemm:014-projection}). It suffices to show that $\{x_i\}_i$ is bounded - any limit point of this sequence will lie in $C$. Otherwise, we may assume $\{x_i\}_i$ is asymptotic with $\mathbb{S}^{m-1}\supset\{\nu(x_i)\}_i\to d$ by replacing $\{C_i\}_i$ by a subsequence. Replacing again $\{C_i\}_i$ by a subsequence, we may assume that $x_i-d\in C_i$ for each $i$. We have:
	\[
		\|x_i\|^{-1}\left(\|x_i\|^2-\|x_i-d\|^2\right)=2d^T\nu(x_i)-\|x_i\|^{-1}\to 2\text{, as }i\to\infty
	\]
	indicating that $x_i-d$ has smaller norm than $x_i$ eventually, which is a contradiction.
\end{proof}

\begin{prop}[Non-empty Intersection II]\label{prop:014-non-empt-II}
	Suppose $C_0\subset \mathbb{R}^m$ is retractive, closed, convex, and that the induced sequence $\{C'_i\}_i:=\{C_0\cap C_i\}_i$ is a sequence of non-empty closed convex subsets, with:
	\[
		R_{C_0}\cap R\subset L
	\]
	then $\{C'_i\}_i$ is retractive, and that $C':=\bigcap_iC'_i\neq\emptyset$.
\end{prop}

\begin{proof}
	Write $R'=\bigcap_iR_{C'_i}$. We have $R'=R_{C_0}\cap R$, so given asymptotic sequence $\{x'_i\}_i$ for $\{C'_i\}_i$ with $\{\nu(x_i)\}_i\to d\in R'\cap \mathbb{S}^{m-1}\subset L$, we have $x'_i-d\in C'_i$ for all $i\geq i_0$ for some $i_0$ by retractiveness of $C'_0$. Non-emptyness of $C'$ is by \Cref{prop:014-non-empt-I}.
\end{proof}

\paragraph{}In this scenario, we have the following "linear + compact" decomposition; compare with \Cref{prop:013-decomposition}.

\begin{coro}[Decomposition into Linear plus Compact]\label{coro:014-decomp-compact}
	When $R=L$, we have $C\neq\emptyset$, and the decomposition $C=L+C\cap L^\perp$.
\end{coro}

\paragraph{}Note that $R_L=R=L,R_{C\cap L^{\perp}}=R\cap L^\perp=L\cap L^\perp=\{0\}$. In other words, this is decomposition into a sum of a linear space containing all the recession directions and a compact convex set.

\begin{proof}
	Use \Cref{prop:013-decomposition} and \Cref{prop:014-non-empt-II} applied to $C_0=\mathbb{R}^m$.
\end{proof}

\subsection{Image, Summations of Closed Convex Sets}

\paragraph{}A nice application of retractive sequence is a condition for closedness of image under affine transformation. For this subsection, fix a convex closed subset $C\subset \mathbb{R}^m$.

\begin{coro}[Closedness under Affine]\label{coro:014-closed-affine}
	Let $C_0\subset \mathbb{R}^m$ be nonempty, retractive, closed, convex, and let $A:\mathbb{R}^m\to \mathbb{R}^n$ be an affine map. If:
	\[
		R_{C_0}\cap R_C\cap \operatorname{ker}(A)\subset L_C
	\]
	then $A(C_0\cap C)$ is closed.
\end{coro}

\begin{proof}
	Given $A(C_0\cap C)\supset\{y_i\}_{i}\to y\in \operatorname{cl}(A(C_0\cap C))$, define $\{C_i\}_i$ by:
	\[
		C_i=C\cap A^{-1}\left(\operatorname{cl}\left(B(y;\|y-y_k\|) \right)\right)
	\]
	then we have $R_{C_i}=R_C\cap \operatorname{ker}(A),L_{C_i}=L_C\cap \operatorname{ker}(A)$ (see (h) of \Cref{prop:013-yoga-linearity} and \Cref{prop:013-yoga-recession}). Therefore, we have by \Cref{prop:014-non-empt-II} that $C_0\cap \bigcap_iC_i\neq\emptyset$. Given $x$ in this set, $y=Ax\in A(C_0\cap C)$.
\end{proof}

\begin{coro}[Closedness under Sum]\label{coro:014-closed-sum}
	Let $\{C_i\}_{i=1}^k$ be nonempty convex subsets in $\mathbb{R}^m$. Let $A:(\mathbb{R}^{m})^k\to \mathbb{R}^m$ be summation map $(x_i)_{i=1}^k\mapsto \sum_{i=1}^kx_i$. Suppose $\left(\bigtimes_{i=1}^kR_{C_i}\right)\cap\operatorname{ker}(A)\subset \left(\bigtimes_{i=1}^kL_{C_i}\right)$, then $\sum_{i=1}^kC_i$ is closed.
\end{coro}

\paragraph{}In other words, if for any given $(d_i)_{i=1}^k\in\bigtimes_{i=1}^kR_{C_i}$ with $\sum_{i=1}^kd_i=0$ that $(d_i)_{i=1}^k\in\bigtimes_{i=1}^kL_{C_i}$, then $\sum_{i=1}^kC_i$ is closed. If $k=2$, the condition is the same as $R_{C_1}\cap -R_{C_2}=\{0\}$.

\begin{proof}
	This is by (b) of \Cref{prop:013-yoga-recession}, \Cref{prop:013-yoga-linearity}, and \Cref{coro:014-closed-affine} with $C_0=\mathbb{R}^{mk}$.
\end{proof}

